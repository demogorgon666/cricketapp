{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flask_sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "from flask import Flask\n",
    "from flask import request,jsonify\n",
    "import json\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error,accuracy_score,confusion_matrix   #r2_score is a score on discrete values\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_string='postgres://postgres:123456@localhost:5432/cricketalpha'\n",
    "db = create_engine(db_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_method(features_train,features_test,labels_train,labels_test,model):\n",
    "        model.fit(features_train,labels_train) #train reandom forest regression model\n",
    "        predict_output = model.predict(features_test) # we are predicting runs_scored(labels)  /// independent variable\n",
    "        return r2_score(labels_test,predict_output),predict_output,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5200/ (Press CTRL+C to quit)\n",
      "C:\\Users\\ashfi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "127.0.0.1 - - [21/Oct/2019 18:15:38] \"\u001b[37mPOST /teamscoringruns HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor RMSE:  62.61010137493953\n",
      "r2_score: 0.6289235949639644\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/teamscoringruns\", methods=[\"POST\"])\n",
    "def team_runs_score_against_team():\n",
    "    \n",
    "    #running the query to get the runs scored by a team\n",
    "#     print(request.get_json().get('team_one'))\n",
    "    query=\"select m.match_id,m.match_type,innings_one_team,innings_two_team,venue_id,sum(d.total_runs) as runs_scored from delivery as d inner join match as m ON d.match_id =m.match_id where innings_one_team = {} and innings_two_team = {} and d.inning =1 group by m.match_type,m.match_id,innings_one_team,innings_two_team,venue_id;\".format(request.get_json().get('team_one'),request.get_json().get('team_two'))\n",
    "    data = {}\n",
    "    if (len(query) == 0):\n",
    "        data.update({\"status\":400})\n",
    "        data.update({\"message\":\"No result found for these teams\"})\n",
    "        return jsonify(data)\n",
    "    if (len(query) <=20 ):\n",
    "        data.update({\"status\":200})\n",
    "        data.update({\"message\":\"very less matches played between the teams cannot predict\"})\n",
    "        return jsonify(data)\n",
    "    else:\n",
    "        #converting the sql data into dataframe\n",
    "        df = pd.read_sql_query(query,db)\n",
    "\n",
    "        # encoding match type ODI,T20 and test ----> 0 is odi, 1 is t20, 2 is test ### 1:- T20, 0:- ODI, 2:- Test\n",
    "        encode = LabelEncoder()\n",
    "\n",
    "        df['match_type'] = encode.fit_transform(df['match_type']) \n",
    "\n",
    "        # assigning the features and labels with train test split\n",
    "        labels = np.array(df['runs_scored']).reshape(-1,1)\n",
    "        features = df.drop(['match_id','runs_scored'],axis=1)\n",
    "\n",
    "        features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size = 0.20)\n",
    "\n",
    "        ##########  USING RANDOM FOREST REGRESSOR\n",
    "        r2score, pred_Rf,modelRandomFr = predict_method(features_train,features_test,labels_train,labels_test,RandomForestRegressor(n_estimators = 50))\n",
    "        print('RandomForestRegressor RMSE: ',math.sqrt(mean_squared_error(labels_test,pred_Rf))) #labels test- predicted value, labels is expected values and predicted values are which the model predict\n",
    "        print('r2_score:',r2score)\n",
    "\n",
    "        if(r2score < 0.40):\n",
    "            data.update({\"status\":200})\n",
    "            data.update({\"message\":\"cannot predict\"})\n",
    "            data.update({\"r2score\":r2score})\n",
    "            return jsonify(data)\n",
    "\n",
    "        ### using random forest regressor to predict\n",
    "\n",
    "        result = modelRandomFr.predict([[request.get_json().get(\"match_type\"),request.get_json().get(\"team_one\"),request.get_json().get(\"team_one\"),request.get_json().get(\"venue_id\")]])[0]\n",
    "\n",
    "        res = str(int(result))\n",
    "        r2score = round(r2score*100,2)\n",
    "    #     data = {}\n",
    "        data.update({\"status\":200})\n",
    "        data.update({\"data\":[{\"prediction\":res}]})\n",
    "        data.update({\"scoring_probability\":r2score})\n",
    "        data.update({\"message\":\"model predicted successfully\"})\n",
    "        return jsonify(data)\n",
    "    \n",
    "# # print(request.data.some)\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False, port=5200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dummy = df_ODI\n",
    "# dummy = dummy.query(\"venue_id == 1\")\n",
    "# encode = LabelEncoder()\n",
    "# df['match_type'] = encode.fit_transform(df['match_type'])  ### 1:- T20, 0:- ODI, 2:- Test\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_remove_duplicate = df[['match_type','inning_one_team','inning_two_team','venue_id','runs_scored']]\n",
    "# df_remove_duplicate = df_remove_duplicate.drop_duplicates()\n",
    "# # df_remove_duplicate.duplicated()\n",
    "# new_df = df_remove_duplicate\n",
    "# new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.array(df['runs_scored']).reshape(-1,1)\n",
    "# features = df.drop(['match_id','runs_scored'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()  #scaler function standardize the data between the range -1 to 1\n",
    "# features= scaler.fit_transform(features)\n",
    "# features\n",
    "# # labels = scaler.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_method(features_train,features_test,labels_train,labels_test,model):\n",
    "#     model.fit(features_train,labels_train) #train reandom forest regression model\n",
    "#     predict_output = model.predict(features_test) # we are predicting runs_scored(labels)  /// independent variable\n",
    "#     return r2_score(labels_test,predict_output),predict_output,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########  USING Decsion tree REGRESSOR\n",
    "# r2score, pred_Decision,modeldecTree = predict_method(features_train,features_test,labels_train,labels_test,DecisionTreeRegressor())\n",
    "# print('DecisionTreeRegressor RMSE: ',math.sqrt(mean_squared_error(labels_test,pred_Decision))) #labels test- predicted value, labels is expected values and predicted values are which the model predict\n",
    "# print('r2_score:',r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##########  USING RANDOM FOREST REGRESSOR\n",
    "# r2score, pred_Rf,modelRandomFr = predict_method(features_train,features_test,labels_train,labels_test,RandomForestRegressor(n_estimators = 50))\n",
    "# print('RandomForestRegressor RMSE: ',math.sqrt(mean_squared_error(labels_test,pred_Rf))) #labels test- predicted value, labels is expected values and predicted values are which the model predict\n",
    "# print('r2_score:',r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df.head(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelRandomFr.predict([[1,1,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_Rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
